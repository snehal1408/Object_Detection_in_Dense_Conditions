{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"Reinforcement_learning_good_images_1024_threshold_0.8.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"z5MiM8ZB9ast"},"source":["# **This colab file shows Reinforcement Learning to detect objects using YOLOv5 and SKU110K-6799_good_images dataset (which is made from after ignoring the corrupted images from subset of SKU110K dataset (SKU110k_6799))**\n","\n","This code is copied from below link (Reference link): \n","\n","1. https://github.com/hsahib2912/Object-detection-reinforcement-learning"]},{"cell_type":"markdown","metadata":{"id":"81jYShmT9z3-"},"source":["# Import Required Libraries"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:32.839601Z","iopub.execute_input":"2021-08-09T16:23:32.840220Z","iopub.status.idle":"2021-08-09T16:23:32.846437Z","shell.execute_reply.started":"2021-08-09T16:23:32.840177Z","shell.execute_reply":"2021-08-09T16:23:32.845620Z"},"trusted":true,"id":"pa2yaJJ7w_k3"},"source":["# Importring libraries\n","import torch\n","import torch.nn as nn\n","from torch.optim import SGD\n","from torch.utils.data import DataLoader\n","from shapely.geometry import Polygon\n","import os\n","import PIL\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import average_precision_score\n","import seaborn as sn\n","import matplotlib.pyplot as plt\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EHow7qfx-F1T"},"source":["# To Use the Dataset \n","\n","* ### There are three ways to use the dataset:\n","\n","1. Download dataset in your local PC and upload dataset directly on colab notebook by clicking on `Files icon in left panel-->right click and upload--->choose dataset path-->click open`. So it will be uploaded in colab notebook. But keep in mind when notebook is connected, you need to upload every time again.\n","\n","2. Download dataset using `!wget` command and unzip it using `!unzip` command. In this option, you need to run the command every time once notebook is disconnected, so it will take long time to download and unzip the dataset, it depends on datset size.\n","\n","3. The best way to use the large datset is to save the dataset in your Google drive and use directly after mounting google drive."]},{"cell_type":"code","metadata":{"id":"mHMNGniI-Uqg"},"source":["# Method 1 is directly upload in colab as explained in above point 1\n","# Method 2\n","# To download and unzip the SKU110K dataset\n","\n","#!wget {URL link to download dataset} # To download the dataset\n","#!tar -xvf {path to untar the dataset} #To untar the dataset\n","#!unzip {path to unzip the dataset} # to unzip the datset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-5AqTxTqkoG","executionInfo":{"status":"ok","timestamp":1631724566944,"user_tz":-60,"elapsed":206,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"30a88d4b-0f63-4127-eb53-31723b45a91f"},"source":["# Method 3\n","# To mount Google drive to use SKU110K-6799_good_images dataset\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"hxwCpqubyVDZ"},"source":["# Initializing the Pre - trained Model\n"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:33.023020Z","iopub.execute_input":"2021-08-09T16:23:33.023668Z","iopub.status.idle":"2021-08-09T16:23:33.316643Z","shell.execute_reply.started":"2021-08-09T16:23:33.023615Z","shell.execute_reply":"2021-08-09T16:23:33.315488Z"},"trusted":true,"id":"4DmS8z8cw_k4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631724580039,"user_tz":-60,"elapsed":3189,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"dca582c9-f2dc-4661-d6ac-d690d3eec2f0"},"source":["# Initialize the pre - trained model that we want to use for reinforcement learning\n","\n","yolo = torch.hub.load('ultralytics/yolov5','custom', path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/SKU110K-6799_16_1024_50_good_images_best.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 ðŸš€ 2021-9-15 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","Fusing layers... \n","Model Summary: 224 layers, 7053910 parameters, 0 gradients\n","Adding AutoShape... \n"]}]},{"cell_type":"markdown","metadata":{"id":"__CpH6ZMPg8q"},"source":["# Set all Path to the Dataset and Results Folder\n","\n","1. Set all train, test and validation folders' path from dataset.\n","2. Set results folder path, where you want to save the results of detected images as well as reinforcement results.\n"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:35.685818Z","iopub.execute_input":"2021-08-09T16:23:35.686266Z","iopub.status.idle":"2021-08-09T16:23:35.690697Z","shell.execute_reply.started":"2021-08-09T16:23:35.686219Z","shell.execute_reply":"2021-08-09T16:23:35.689804Z"},"trusted":true,"id":"G-4q-Xraw_k8"},"source":["# Set all path\n","base_img_train_path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/SKU110K-6799-good_images/SKU110K-6799-good_images/training_pano/images/'\n","base_label_train_path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/SKU110K-6799-good_images/SKU110K-6799-good_images/training_pano/labels/'\n","base_img_test_path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/SKU110K-6799-good_images/SKU110K-6799-good_images/validation_pano/images/'\n","base_label_test_path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/SKU110K-6799-good_images/SKU110K-6799-good_images/validation_pano/labels/'\n","base_img_q_results_path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/Reinforcement_results/test_results/'\n","yolo_path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/Reinforcement_results/'\n","detected_images_path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/Reinforcement_results/detected_images/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xp5EKqIyPoFo"},"source":["# Define all the Functions that are Used to Draw Evaluation Curves and also used while Training, Testing and Detecting Procedure\n","\n","1. Function to Get the Ground Truth Co - Ordinates of Bounding Boxes in Numpy Array."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:36.574396Z","iopub.execute_input":"2021-08-09T16:23:36.574931Z","iopub.status.idle":"2021-08-09T16:23:36.580464Z","shell.execute_reply.started":"2021-08-09T16:23:36.574897Z","shell.execute_reply":"2021-08-09T16:23:36.579750Z"},"trusted":true,"id":"YaolaPqnw_k9"},"source":["def get_labels_into_pandas(img,pth):\n","    img = img[:len(img)-3]+'txt'\n","    path = pth+img\n","    df = pd.read_csv(path,delimiter = ' ',header  = None)\n","    df.drop(0, inplace=True, axis=1)\n","    return np.array(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2FYygr5QEMh"},"source":["2. Function to Get the Results from YOLOV5 Pre - trained Model"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:37.449460Z","iopub.execute_input":"2021-08-09T16:23:37.450085Z","iopub.status.idle":"2021-08-09T16:23:37.455936Z","shell.execute_reply.started":"2021-08-09T16:23:37.450052Z","shell.execute_reply":"2021-08-09T16:23:37.454982Z"},"trusted":true,"id":"Lzp3ADNyw_k_"},"source":["def get_yolo_results(img,base_img_path):\n","    result = yolo(base_img_path+img)\n","    df = result.pandas().xywhn[0]\n","    df.drop('confidence',inplace = True,axis = 1)\n","    df.drop('class',inplace = True,axis = 1)\n","    df.drop('name',inplace = True,axis = 1)\n","    return np.array(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58ykptbVQkNl"},"source":["3. This Function Sorts Ground Truth Labels According to the Results We Get While Passing Images to YOLOV5 Model; Such that Absolute Distance between Ground Truth and Prediction is Minimum."]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:38.109487Z","iopub.execute_input":"2021-08-09T16:23:38.110068Z","iopub.status.idle":"2021-08-09T16:23:38.117734Z","shell.execute_reply.started":"2021-08-09T16:23:38.110030Z","shell.execute_reply":"2021-08-09T16:23:38.116656Z"},"trusted":true,"id":"j0QGSJ_ow_lA"},"source":["def get_sorted(x,y):\n","    res = []\n","    for i in x:\n","        min_diff = 100000\n","        im = y[0]\n","        for j in y:\n","            diff = abs(i[0]-j[0])+abs(i[1]-j[1])+abs(i[2]-j[2])+abs(i[3]-j[3])\n","            if(diff<min_diff):\n","                min_diff = diff\n","                im = j\n","        res.append(im)\n","    return np.array(res)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TAtc8763Q9A8"},"source":["4. Function to Compute Intersection Of Union"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:44.061456Z","iopub.execute_input":"2021-08-09T16:23:44.061904Z","iopub.status.idle":"2021-08-09T16:23:44.070599Z","shell.execute_reply.started":"2021-08-09T16:23:44.061866Z","shell.execute_reply":"2021-08-09T16:23:44.069447Z"},"trusted":true,"id":"vQDyyOG_w_lA"},"source":["def compute_IOU(b1,b2):\n","    xmin1,xmax1,ymin1,ymax1 = b1[0],b1[1],b1[2],b1[3]\n","    xmin2,xmax2,ymin2,ymax2 = b2[0],b2[1],b2[2],b2[3]\n","    p1 = Polygon([[xmin1,ymin1],[xmax1,ymin1],[xmax1,ymax1],[xmin1,ymax1]])\n","    p2 = Polygon([[xmin2,ymin2],[xmax2,ymin2],[xmax2,ymax2],[xmin2,ymax2]])\n","    a = p1.intersection(p2).area\n","    b = p1.union(p2).area\n","    if(b!=0):\n","      iou = a / b\n","      return iou\n","    else:\n","      return 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o-E3puEhRCdF"},"source":["5. Function to Transform Labels from : [ x_center, y_center, width, height ] to => [ x_min, x_max, y_min, y_max ] "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:44.078164Z","iopub.execute_input":"2021-08-09T16:23:44.078751Z","iopub.status.idle":"2021-08-09T16:23:44.089364Z","shell.execute_reply.started":"2021-08-09T16:23:44.078713Z","shell.execute_reply":"2021-08-09T16:23:44.088502Z"},"trusted":true,"id":"78wSMH0xw_lB"},"source":["def transform_y(y,w,h):\n","    y[:,0] *= w\n","    y[:,1] *= h\n","    y[:,2] *= w\n","    y[:,3] *= h\n","    for i in range(len(y)):\n","        xmin = y[i][0]-(y[i][2]/2)\n","        xmax = y[i][0]+(y[i][2]/2)\n","        ymin = y[i][1]-(y[1][3]/2)\n","        ymax = y[i][1]-(y[1][3]/2)\n","        y[i][0],y[i][1],y[i][2],y[i][3] = xmin/w,xmax/w,ymin/h,ymax/h\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Y3F-8bcfk-Q","executionInfo":{"status":"ok","timestamp":1631724622351,"user_tz":-60,"elapsed":206,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"b8d8326c-fb97-4eb1-858c-74c99bf881d5"},"source":["len(os.listdir(base_img_test_path)) # to find the no. of test samples"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["350"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"5vm-JfG1ReFF"},"source":["6. Function to Write Results We Get from DeepQNetwork into CSV"]},{"cell_type":"code","metadata":{"id":"HkJHhX4JL4mz"},"source":["def write_csv(full_y,img):\n","  img = img[:len(img)-3]+'csv'\n","  path = '/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/Reinforcement_results/test_results/'+img\n","  df = pd.DataFrame(full_y)\n","  df.to_csv(path,index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FCnRoX-MRuhC"},"source":["7. This Function Computes Minimum Squared Error"]},{"cell_type":"code","metadata":{"id":"Fht9QKuqKrme"},"source":["def get_mse(y1,y2):\n","    s = 0\n","    for i in range(len(y1)):\n","        s = (y1[i] - y2[i])**2\n","    return s/len(y1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6pF8dCz8zOf4"},"source":["8. Function to Define the Deep Q Network"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:23:44.126390Z","iopub.execute_input":"2021-08-09T16:23:44.126802Z","iopub.status.idle":"2021-08-09T16:23:44.141472Z","shell.execute_reply.started":"2021-08-09T16:23:44.126765Z","shell.execute_reply":"2021-08-09T16:23:44.140268Z"},"trusted":true,"id":"hwdq3IZ4w_lE"},"source":["class DeepQNetwork(nn.Module):\n","    def __init__(self):\n","        super(DeepQNetwork, self).__init__()\n","        self.hidden1 = nn.Linear(5,100)\n","        nn.init.xavier_uniform_(self.hidden1.weight)\n","        self.activation1 = nn.Tanh()\n","        self.d1 = nn.Dropout(p = 0.2)\n","        self.hidden2 = nn.Linear(100,1000)\n","        nn.init.xavier_uniform_(self.hidden2.weight)\n","        self.activation2= nn.Tanh()\n","        self.d2 = nn.Dropout(p = 0.2)\n","        self.hidden3= nn.Linear(1000,4)\n","        nn.init.xavier_uniform_(self.hidden3.weight)\n","        self.activation3 = nn.Tanh()\n","        \n","    def forward(self,X):\n","        X = self.hidden1(X)\n","        X = self.activation1(X)\n","        X = self.d1(X)\n","        X = self.hidden2(X)\n","        X = self.activation2(X)\n","        X = self.d2(X)\n","        X = self.hidden3(X)\n","        X = self.activation3(X)\n","        return X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hrRxl33SRxYn"},"source":["9. Function to Train the Model"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:33:33.233592Z","iopub.execute_input":"2021-08-09T16:33:33.233985Z","iopub.status.idle":"2021-08-09T16:33:33.246489Z","shell.execute_reply.started":"2021-08-09T16:33:33.233953Z","shell.execute_reply":"2021-08-09T16:33:33.245598Z"},"trusted":true,"id":"S-X7bk2pw_lE"},"source":["def train(model):\n","    loss_l = []\n","    mse = nn.MSELoss()\n","    opt = SGD(model.parameters(),lr = 0.01,momentum = 0.9)\n","    cnt = 0\n","    img_list = os.listdir(base_img_train_path)\n","    loss_list = []\n","    for img in img_list:\n","        w,h = PIL.Image.open(base_img_train_path+img).size\n","        x = torch.from_numpy(get_yolo_results(img,base_img_train_path))\n","        y = get_sorted(x,get_labels_into_pandas(img,base_label_train_path))\n","        y = transform_y(y,w,h)\n","        y = torch.from_numpy(y)\n","        reward = torch.tensor([1])\n","        if (len(x)!=0 and len(y)!=0):\n","            for epoch in range(1):\n","                for i in range(len(x)):\n","                    opt.zero_grad()\n","                    new_x = torch.cat((x[i],reward))\n","                    yhat = model(new_x.float())\n","                    loss = mse(yhat.float(),y[i].float())\n","                    loss.backward()\n","                    iou = compute_IOU(yhat,y[i])\n","                    if(iou>0.8):# To set threshold value at 0.8\n","                        reward = torch.tensor([1])\n","                    else:\n","                        reward = torch.tensor([-1])\n","                    opt.step()\n","        loss_list.append(loss)\n","        if(cnt%200==0):\n","            print('Training sample = ',cnt)\n","            print('loss = ',loss)\n","        cnt+=1\n","    torch.save(model.state_dict(),'/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/Reinforcement_results/DenseQNet.pt')\n","    loss_df = pd.DataFrame(loss_list)\n","    loss_df.to_csv('/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/Reinforcement_results/loss.csv',index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zv3xCjnCR1s5"},"source":["10. Funcion to Test the Model. It Stores Co - Ordinates of Bounding Boxes to a CSV file."]},{"cell_type":"code","metadata":{"id":"bkDSPa6gKuGq"},"source":["def test(model):\n","  mse_l = []\n","  iou_l = []\n","  img_list = os.listdir(base_img_test_path)\n","  cnt = 0\n","  for img in img_list:\n","    try:\n","      w,h = PIL.Image.open(base_img_test_path+img).size\n","      x = torch.from_numpy(get_yolo_results(img,base_img_test_path))\n","      y_org = get_sorted(x,get_labels_into_pandas(img,base_label_test_path))\n","      y = transform_y(y_org,w,h)\n","      y = torch.from_numpy(y)\n","      reward = torch.tensor([1])\n","      iou = mse = 0\n","      full_y = []\n","      if (len(x)!=0 and len(y)!=0):\n","          for i in range(len(x)):\n","              new_x = torch.cat((x[i],reward))\n","              yhat = model(new_x.float())\n","              mse += get_mse(yhat,y[i]).float()\n","              iou += compute_IOU(y_org[i],x[i])\n","              full_y.append(list(map(abs,yhat.tolist())))\n","      iou_l.append(iou/len(y_org))\n","      mse_l.append(mse/len(y_org))\n","      write_csv(full_y,img)\n","      if(cnt%20==0):\n","        print('Testing Sample = ',cnt)\n","      cnt+=1\n","    except:\n","      print(\"Skipping \",img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7oNVAl8YB9RR"},"source":["# Train the Model"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:32:39.451676Z","iopub.execute_input":"2021-08-09T16:32:39.452081Z","iopub.status.idle":"2021-08-09T16:33:09.615920Z","shell.execute_reply.started":"2021-08-09T16:32:39.452048Z","shell.execute_reply":"2021-08-09T16:33:09.613801Z"},"trusted":true,"id":"MybnNNO9w_lF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628693054686,"user_tz":-60,"elapsed":12898660,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"70d52de0-5076-4880-8261-4704b085a96d"},"source":["model = DeepQNetwork()\n","train(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training sample =  0\n","loss =  tensor(0.09775, grad_fn=<MseLossBackward>)\n","Training sample =  200\n","loss =  tensor(6.10891e-05, grad_fn=<MseLossBackward>)\n","Training sample =  400\n","loss =  tensor(0.00784, grad_fn=<MseLossBackward>)\n","Training sample =  600\n","loss =  tensor(0.00414, grad_fn=<MseLossBackward>)\n","Training sample =  800\n","loss =  tensor(0.00126, grad_fn=<MseLossBackward>)\n","Training sample =  1000\n","loss =  tensor(0.00392, grad_fn=<MseLossBackward>)\n","Training sample =  1200\n","loss =  tensor(0.00037, grad_fn=<MseLossBackward>)\n","Training sample =  1400\n","loss =  tensor(0.00145, grad_fn=<MseLossBackward>)\n","Training sample =  1600\n","loss =  tensor(0.00467, grad_fn=<MseLossBackward>)\n","Training sample =  1800\n","loss =  tensor(0.00029, grad_fn=<MseLossBackward>)\n","Training sample =  2000\n","loss =  tensor(0.00228, grad_fn=<MseLossBackward>)\n","Training sample =  2200\n","loss =  tensor(0.00054, grad_fn=<MseLossBackward>)\n","Training sample =  2400\n","loss =  tensor(0.00399, grad_fn=<MseLossBackward>)\n","Training sample =  2600\n","loss =  tensor(0.00240, grad_fn=<MseLossBackward>)\n","Training sample =  2800\n","loss =  tensor(0.00399, grad_fn=<MseLossBackward>)\n","Training sample =  3000\n","loss =  tensor(0.00485, grad_fn=<MseLossBackward>)\n","Training sample =  3200\n","loss =  tensor(0.00128, grad_fn=<MseLossBackward>)\n","Training sample =  3400\n","loss =  tensor(0.00379, grad_fn=<MseLossBackward>)\n","Training sample =  3600\n","loss =  tensor(0.00156, grad_fn=<MseLossBackward>)\n","Training sample =  3800\n","loss =  tensor(0.00042, grad_fn=<MseLossBackward>)\n","Training sample =  4000\n","loss =  tensor(0.00117, grad_fn=<MseLossBackward>)\n","Training sample =  4200\n","loss =  tensor(0.00087, grad_fn=<MseLossBackward>)\n","Training sample =  4400\n","loss =  tensor(0.00046, grad_fn=<MseLossBackward>)\n","Training sample =  4600\n","loss =  tensor(0.00261, grad_fn=<MseLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ygddmvJbCNoF"},"source":["# To initialize the Evaluation Mode"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:04:51.469309Z","iopub.status.idle":"2021-08-09T16:04:51.469779Z"},"trusted":true,"id":"hNjkOiG2w_lG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631724661324,"user_tz":-60,"elapsed":250,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"aae5dbfc-e668-4988-d0fa-37eb38417e28"},"source":["model = DeepQNetwork()\n","model.load_state_dict(torch.load('/content/gdrive/MyDrive/Object_Detection_in_Dense_Conditions/Reinforcement_results/DenseQNet.pt'))\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeepQNetwork(\n","  (hidden1): Linear(in_features=5, out_features=100, bias=True)\n","  (activation1): Tanh()\n","  (d1): Dropout(p=0.2, inplace=False)\n","  (hidden2): Linear(in_features=100, out_features=1000, bias=True)\n","  (activation2): Tanh()\n","  (d2): Dropout(p=0.2, inplace=False)\n","  (hidden3): Linear(in_features=1000, out_features=4, bias=True)\n","  (activation3): Tanh()\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"aV1Un-n8CX1c"},"source":["# Test the Model"]},{"cell_type":"code","metadata":{"id":"0xOcq4fj25x6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628758433134,"user_tz":-60,"elapsed":718868,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"24ba6fe0-27c6-4d6f-dd31-333f76228b00"},"source":["test(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Testing Sample =  0\n","Testing Sample =  20\n","Testing Sample =  40\n","Testing Sample =  60\n","Testing Sample =  80\n","Testing Sample =  100\n","Testing Sample =  120\n","Testing Sample =  140\n","Testing Sample =  160\n","Testing Sample =  180\n","Testing Sample =  200\n","Testing Sample =  220\n","Testing Sample =  240\n","Testing Sample =  260\n","Testing Sample =  280\n","Testing Sample =  300\n","Testing Sample =  320\n","Testing Sample =  340\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VZwdEHUnCc6v"},"source":["11. Function to Compute the Confusion Matrix"]},{"cell_type":"code","metadata":{"id":"kkDqARye0vLR"},"source":["def compute_confusion_matrix(model):\n","  map_l = []\n","  tp_l = []\n","  fp_l = []\n","  fn_l = []\n","  img_list = os.listdir(base_img_test_path)\n","  cnt = 0\n","  for img in img_list:\n","    tp = fp = fn = map = 0\n","    csv_path = img[:len(img)-3]+'csv'\n","    w,h = PIL.Image.open(base_img_test_path+img).size\n","    x = get_yolo_results(img,base_img_test_path)\n","    y_org = get_labels_into_pandas(img,base_label_test_path)\n","    y = transform_y(y_org,w,h)\n","    fn = abs(len(x)-len(y_org))\n","    yhat = pd.read_csv(base_img_q_results_path+csv_path).to_numpy()\n","    vec = [1,1,0,0]\n","    for i in range(min(len(yhat),len(y))):\n","      err = get_mse(yhat[i],y[i])\n","      if(err>0.1):\n","        fp+=1\n","      else:\n","        tp+=1\n","      map += average_precision_score(vec,yhat[i])\n","    tp_l.append(tp)\n","    fp_l.append(fp)\n","    fn_l.append(fn)\n","    map_l.append(map/len(yhat))\n","    if(cnt%20 == 0):\n","      print(\"At image = \",cnt)\n","    cnt+=1\n","  pd.DataFrame(tp_l).to_csv(yolo_path+'tp.csv',index = False)\n","  pd.DataFrame(fp_l).to_csv(yolo_path+'fp.csv',index = False)\n","  pd.DataFrame(fn_l).to_csv(yolo_path+'fn.csv',index = False)\n","  pd.DataFrame(map_l).to_csv(yolo_path+'map.csv',index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_0bJYNv00vK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631725858903,"user_tz":-60,"elapsed":100676,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"9022169b-0a4c-46c4-d588-c283e8fdd59a"},"source":["compute_confusion_matrix(model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["At image =  0\n","At image =  20\n","At image =  40\n","At image =  60\n","At image =  80\n","At image =  100\n","At image =  120\n","At image =  140\n","At image =  160\n","At image =  180\n","At image =  200\n","At image =  220\n","At image =  240\n","At image =  260\n","At image =  280\n","At image =  300\n","At image =  320\n","At image =  340\n"]}]},{"cell_type":"markdown","metadata":{"id":"4MmiIBDRdBKh"},"source":["# To Find the Evaluation Matrix"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJfx-tAwcsF5","executionInfo":{"status":"ok","timestamp":1631726030239,"user_tz":-60,"elapsed":165,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"94c70e1e-692e-42a4-d14a-cab4fbe6295a"},"source":["# Reference links:\n","# 1)https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n","# 2)https://www.geeksforgeeks.org/python-pandas-series-tolist/\n","# 3)https://www.analyticsvidhya.com/blog/2020/09/precision-recall-machine-learning/\n","tp_l = pd.read_csv(yolo_path+'tp.csv')['0'].to_list()\n","fp_l = pd.read_csv(yolo_path+'fp.csv')['0'].to_list()\n","fn_l = pd.read_csv(yolo_path+'fn.csv')['0'].to_list()\n","map_l = pd.read_csv(yolo_path+'map.csv')['0'].to_list()\n","tp = sum(tp_l)\n","fp = sum(fp_l)\n","fn = sum(fn_l)\n","total = tp+fp+fn\n","map = sum(map_l)/len(map_l)\n","print('True Positives = ',tp)\n","print('False Positives = ',fp)\n","print('False Neagtives = ',fn)\n","print('Mean Average Precision = ',map)\n","print(\"Accuracy = \",100*tp/total,'%')\n","print(\"Precision = \",100*tp/(fp+tp),'%')\n","print('Recall = ',100*tp/(fn+tp),'%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True Positives =  49148\n","False Positives =  2368\n","False Neagtives =  6923\n","Mean Average Precision =  0.6561117988969201\n","Accuracy =  84.10137066000445 %\n","Precision =  95.40336982684991 %\n","Recall =  87.65315403684615 %\n"]}]},{"cell_type":"markdown","metadata":{"id":"QTKPcnOVDhN2"},"source":["# To Draw and Save Confusion Matrix Figure"]},{"cell_type":"code","metadata":{"id":"rruxOdDv1Dj8"},"source":["arr = [[tp,fp],[fn,0]]\n","confusion_df = pd.DataFrame(arr,index = ['Positive','Negative'],columns = ['Positive','Negative'])\n","plt.figure(figsize = (10,7))\n","sn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 15})\n","plt.ylabel('Predicted Values')\n","plt.xlabel('Actual Values')\n","plt.savefig(yolo_path+'confusion.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pqSkbrMlDtD4"},"source":["# To Draw and Save Loss Curve"]},{"cell_type":"code","metadata":{"id":"qmS8HsGC1IL_"},"source":["plt.clf()\n","loss_l = pd.read_csv(yolo_path+'loss.csv')['0'].to_list()\n","loss_l = [float(i[7:14]) for i in loss_l]\n","plt.plot(loss_l)\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.savefig(yolo_path+'loss.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XzhZpZlcDzB5"},"source":["# To Draw and Save mAP(Mean Average Precision) Curve"]},{"cell_type":"code","metadata":{"id":"SV1niQjW1tnz"},"source":["plt.clf()\n","map_l = pd.read_csv(yolo_path+'map.csv')['0'].to_list()\n","mean = [0.6561117988969201 for i in range(len(map_l))]\n","plt.plot(loss_l)\n","plt.plot(mean)\n","plt.xlabel('Image')\n","plt.ylabel('Average Precision')\n","plt.savefig(yolo_path+'map.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZZ_LD42FEL-8"},"source":["12. Function to detect objects from Images"]},{"cell_type":"code","metadata":{"id":"B07h8uj2m9V7"},"source":["def k():\n","  return int(np.random.normal(0,30,1)[0])\n","def get_images():\n","  img_list = os.listdir(base_img_test_path)\n","  cnt = 0\n","  for img in img_list:\n","    path = base_img_test_path+img\n","    cvimg = cv2.imread(path)\n","    res = yolo(path).pandas().xyxy[0]\n","    lab = img[:len(img)-3]+'csv'\n","    for i in range(len(res)):\n","      xmin = int(res['xmin'][i]+k())\n","      xmax = int(res['xmax'][i]+k())\n","      ymax = int(res['ymax'][i]+k())\n","      ymin = int(res['ymin'][i]+k())\n","      cvimg = cv2.rectangle(cvimg, (xmin,ymin), (xmax,ymax), (120,255,255), 10)\n","      cv2.putText(cvimg, str(res['confidence'][i])[:5], (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (120,255,255), 5)\n","    cv2.imwrite(detected_images_path+img, cvimg)\n","    if(cnt%20 == 0):\n","      print('At image = ',cnt)\n","    cnt+=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N4xJYHy5EdZC"},"source":["# To Save Detected Images"]},{"cell_type":"code","metadata":{"id":"fKx0nYYHyIxW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631728416093,"user_tz":-60,"elapsed":208706,"user":{"displayName":"snehal desai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisnRT1BHHCHN6bQBg49fvUCbrGKT_G74JRwbnl=s64","userId":"08420235973951776316"}},"outputId":"2b67926e-8599-4b30-a169-fb938c513e99"},"source":["get_images()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["At image =  0\n","At image =  20\n","At image =  40\n","At image =  60\n","At image =  80\n","At image =  100\n","At image =  120\n","At image =  140\n","At image =  160\n","At image =  180\n","At image =  200\n","At image =  220\n","At image =  240\n","At image =  260\n","At image =  280\n","At image =  300\n","At image =  320\n","At image =  340\n"]}]}]}